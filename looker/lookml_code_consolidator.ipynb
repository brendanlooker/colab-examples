{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9m+YfmZAWOb0IHJ+Jc8Qs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brendanlooker/colab-examples/blob/main/looker/lookml_code_consolidator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tClVRmig00p8",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "\n",
        "!pip install looker_sdk\n",
        "!pip install lkml     # https://lkml.readthedocs.io/en/latest/\n",
        "!pip install PyGithub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import glob\n",
        "import looker_sdk\n",
        "from looker_sdk import models40\n",
        "import os\n",
        "from git import Repo\n",
        "import re\n",
        "import lkml\n",
        "from collections.abc import Hashable\n",
        "from getpass import getpass"
      ],
      "metadata": {
        "id": "94ar2MvJ053t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Config Looker Connection\n",
        "\n",
        "os.environ[\"LOOKERSDK_BASE_URL\"] = \"https://0a008a8e-ad98-4f2e-95c4-99bcdc1ff974.looker.app\"       # Update to reference valis Looker instance\n",
        "os.environ[\"LOOKERSDK_CLIENT_ID\"] = input(\"Enter Looker Client ID: \")          # Add API Client ID\n",
        "os.environ[\"LOOKERSDK_CLIENT_SECRET\"] = getpass(\"Enter Looker Client Secret: \") # Add API Client ID"
      ],
      "metadata": {
        "id": "4Xd9qICs08F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Authenticatin to Looker\n",
        "\n",
        "sdk = looker_sdk.init40()\n",
        "\n",
        "me = sdk.me(fields=\"email\")\n",
        "print(me.email)"
      ],
      "metadata": {
        "id": "GRCx3fIA0-R1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all LookML files\n",
        "# Specify the Looker Project Id\n",
        "# Only view files are considered\n",
        "\n",
        "project_id = \"lg_demo_env\" #@param {type:\"string\"}\n",
        "\n",
        "all_files = sdk.all_project_files(project_id=project_id, fields=\"id\")\n",
        "\n",
        "file_list = []\n",
        "for file in all_files:\n",
        "    if file.id.endswith(\"view.lkml\"):\n",
        "        file_details = (file.id,os.path.basename(file.id))\n",
        "        file_list.append(file_details)\n",
        "print(file_list)"
      ],
      "metadata": {
        "id": "G1mxK7Gj1AQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in file_list:\n",
        "  print(file[0])"
      ],
      "metadata": {
        "id": "_cPoCgSv1CAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get git remote url associated with Looker project via Looker SDK\n",
        "\n",
        "\n",
        "git_remote_url = sdk.project(\n",
        "    project_id=project_id)\n",
        "\n",
        "print(git_remote_url.git_remote_url)\n",
        "\n",
        "pattern = r\"git@github\\.com:(.*?)/(.*?).git\"\n",
        "match = re.match(pattern,git_remote_url.git_remote_url)\n",
        "\n",
        "if match:\n",
        "    repo_owner, repo_name = match.groups()\n",
        "    print(f\"Repo Owner: {repo_owner}\")\n",
        "    print(f\"Repo Name: {repo_name}\")\n"
      ],
      "metadata": {
        "id": "nMPnkdpt1Em0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone Repo\n",
        "# You can simply run a command like the one below to clone the repo locally (you will need to authenticate)\n",
        "# Once cloned you can begin to run the code to compare LookML objects across files\n",
        "\n",
        "# !git clone https://gitlab.com/yourusername/yourrepository.git\n",
        "\n",
        "# Alternative use GitHub API\n",
        "github_token = \"\"  # @param {type:\"string\"}\n",
        "repo_url = f\"https://{github_token}@github.com/{repo_owner}/{repo_name}.git\"  # Use token in the URL\n",
        "local_dir = f\"./{project_id}\"\n",
        "\n",
        "# Clone repo if not already cloned\n",
        "if not os.path.exists(local_dir):\n",
        "    Repo.clone_from(repo_url, local_dir)\n",
        "    print(\"Repository cloned locally.\")\n",
        "else:\n",
        "    print(\"Repository already exists locally.\")"
      ],
      "metadata": {
        "id": "ufsYKECI1GnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper class that encapsulates all functionality related to\n",
        "# parsing LookML files, extracting relevant fields, comparing them,\n",
        "# and writing the output to new files.\n",
        "\n",
        "class LookMLHandler:\n",
        "    @staticmethod\n",
        "    def parse_lookml_file(file_path):\n",
        "      # Load LookML file and parse its content into a Python dictionary\n",
        "        print(f\"Parsing LookML file: {file_path}\")\n",
        "        with open(file_path, \"r\") as file:\n",
        "            content = file.read()\n",
        "        return lkml.load(content)\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_fields(lookml_data):\n",
        "      # Extract all dimensions, dimension groups and measures from the LookML file\n",
        "        dimensions = {}\n",
        "        measures = {}\n",
        "        dimension_groups = {}\n",
        "        for view in lookml_data.get(\"views\", []):\n",
        "\n",
        "            # Extract dimensions\n",
        "            for dimension in view.get(\"dimensions\", []):\n",
        "                name = dimension.get(\"name\")\n",
        "                # Store all attributes except the name for comparison\n",
        "                attributes = {k: v for k, v in dimension.items() if k != \"name\"}\n",
        "                dimensions[name] = attributes\n",
        "\n",
        "            # Extract dimension groups\n",
        "            for dimension_group in view.get(\"dimension_groups\", []):\n",
        "                name = dimension_group.get(\"name\")\n",
        "                attributes = {k: v for k, v in dimension_group.items() if k != \"name\"}\n",
        "                dimension_groups[name] = attributes\n",
        "\n",
        "            # Extract measures\n",
        "            for measure in view.get(\"measures\", []):\n",
        "                name = measure.get(\"name\")\n",
        "                attributes = {k: v for k, v in measure.items() if k != \"name\"}\n",
        "                measures[name] = attributes\n",
        "\n",
        "        print(f\"Extracted dimensions: {dimensions.keys()}\")\n",
        "        print(f\"Extracted dimension_groups: {dimension_groups.keys()}\")\n",
        "        print(f\"Extracted measures: {measures.keys()}\")\n",
        "        return dimensions, dimension_groups, measures\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def make_hashable(attrs):\n",
        "      # Convert attributes into a fully hashable format for set comparison\n",
        "        def freeze(x):\n",
        "            if isinstance(x, dict):\n",
        "                return frozenset((k, freeze(v)) for k, v in x.items())\n",
        "            if isinstance(x, list):\n",
        "                return tuple(freeze(i) for i in x)\n",
        "            return x if isinstance(x, Hashable) else str(x)\n",
        "        return freeze(attrs)\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def write_identical_fields(identical_dims, identical_dim_groups, identical_measures, output_file):\n",
        "      # Write all identical dimensions, dimension groups and measures to a LookML file\n",
        "        print(f\"Writing identical fields to {output_file}\")\n",
        "        lookml_structure = {\n",
        "            \"views\": [\n",
        "                {\n",
        "                    \"name\": \"identical_fields\",\n",
        "                    \"dimensions\": [\n",
        "                        {\"name\": name, **attributes} for name, attributes in identical_dims.items()\n",
        "                    ],\n",
        "                    \"dimension_groups\": [\n",
        "                        {\"name\": name, **attributes} for name, attributes in identical_dim_groups.items()\n",
        "                    ],\n",
        "                    \"measures\": [\n",
        "                        {\"name\": name, **attributes} for name, attributes in identical_measures.items()\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "        with open(output_file, \"w\") as file:\n",
        "            file.write(lkml.dump(lookml_structure))\n",
        "        print(f\"Identical fields written successfully to {output_file}\")\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def remove_identical_from_file(file_path, identical_dims, identical_dim_groups, identical_measures):\n",
        "      # Remove matching fields from the original file to avoid duplication\n",
        "        print(f\"Removing identical fields from {file_path}\")\n",
        "        with open(file_path, \"r\") as file:\n",
        "            lookml_data = lkml.load(file)\n",
        "\n",
        "        modified = False\n",
        "        for view in lookml_data.get(\"views\", []):\n",
        "\n",
        "            view[\"dimensions\"] = [\n",
        "                d for d in view.get(\"dimensions\", []) if d.get(\"name\") not in identical_dims\n",
        "            ]\n",
        "\n",
        "            view[\"dimension_groups\"] = [\n",
        "                dimension_group for dimension_group in view.get(\"dimension_groups\", [])\n",
        "                if dimension_group.get(\"name\") not in identical_dim_groups\n",
        "            ]\n",
        "\n",
        "            view[\"measures\"] = [\n",
        "                m for m in view.get(\"measures\", []) if m.get(\"name\") not in identical_measures\n",
        "            ]\n",
        "            modified |= True\n",
        "\n",
        "        if modified:\n",
        "\n",
        "            # Add the comment at the beginning of the file\n",
        "            comment = \"# Code modified as part of code consolidation effort, common objects have been moved to identical_fields.lkml\\n\\n\"\n",
        "\n",
        "            # Convert the LookML data back to a string\n",
        "            updated_content = comment + lkml.dump(lookml_data)\n",
        "\n",
        "\n",
        "            with open(file_path, \"w\") as file:\n",
        "                  file.write(updated_content)\n",
        "                # file.write(lkml.dump(lookml_data))\n",
        "            print(f\"Removed identical fields from {file_path}\")\n",
        "        else:\n",
        "            print(f\"No identical fields found in {file_path} to remove\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hTqvsq8L_OnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function\n",
        "\n",
        "\n",
        "def compare_lookml_files(file_paths, output_file):\n",
        "  # Main function that coordinates parsing, comparison, output, and cleanup\n",
        "    handler = LookMLHandler()\n",
        "    common_dims = None\n",
        "    common_dim_groups = None\n",
        "    common_measures = None\n",
        "\n",
        "    # Go through each file to extract and hash its fields for set comparison\n",
        "    for idx, file_path in enumerate(file_paths):\n",
        "        lookml_data = handler.parse_lookml_file(file_path)\n",
        "        dims, dim_groups, measures = handler.extract_fields(lookml_data)\n",
        "\n",
        "        # Convert dimensions/measures to a hashable set of (name, attributes)\n",
        "        dims_set = set((name, handler.make_hashable(attrs)) for name, attrs in dims.items())\n",
        "        dim_groups_set = set((name, handler.make_hashable(attrs)) for name, attrs in dim_groups.items())\n",
        "        measures_set = set((name, handler.make_hashable(attrs)) for name, attrs in measures.items())\n",
        "\n",
        "        # For the first file, initialize the comparison sets\n",
        "        if idx == 0:\n",
        "            common_dims = dims_set\n",
        "            common_dim_groups = dim_groups_set\n",
        "            common_measures = measures_set\n",
        "        else:\n",
        "            # Perform intersection to retain only fields common across all files\n",
        "            common_dims &= dims_set\n",
        "            common_dim_groups &= dim_groups_set\n",
        "            common_measures &= measures_set\n",
        "\n",
        "    # Reconstruct dictionaries from common entries\n",
        "    identical_dims = {name: dict(attrs) for name, attrs in common_dims} if common_dims else {}\n",
        "    identical_dim_groups = {name: dict(attrs) for name, attrs in common_dim_groups} if common_dim_groups else {}\n",
        "    identical_measures = {name: dict(attrs) for name, attrs in common_measures} if common_measures else {}\n",
        "\n",
        "    # If common fields exist, write and clean them from the original files\n",
        "    if identical_dims or identical_dim_groups or identical_measures:\n",
        "        print(f\"‚úÖ Identical dimensions found: {list(identical_dims.keys())}\")\n",
        "        print(f\"‚úÖ Identical dimension groups found: {list(identical_dim_groups.keys())}\")\n",
        "        print(f\"‚úÖ Identical measures found: {list(identical_measures.keys())}\")\n",
        "        handler.write_identical_fields(identical_dims, identical_dim_groups, identical_measures, output_file)\n",
        "        for file_path in file_paths:\n",
        "            handler.remove_identical_from_file(file_path, identical_dims, identical_dim_groups, identical_measures)\n",
        "        print(\"‚úÖ Processing complete. Identical fields removed and saved.\")\n",
        "    else:\n",
        "        print(\"No identical fields found across all files.\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tqyubPxS9Eof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Base dir where LookML code is located\n",
        "local_base_dir = f\"/content/{project_id}/\"\n",
        "\n",
        "# Folder from where to perform the search\n",
        "# For example, if your LookML project contains a root folder named \"Views\"\n",
        "# You can seach all objects recursively by setting the folder variable to \"Views\"\n",
        "# You can also restrict the seach by specifying a specific path (e.g. \"Views/cc\")\n",
        "folder = \"Views\" #@param {type:\"string\"}\n",
        "\n",
        "# Set the folder path based on the folder value specified\n",
        "folder_path = f\"{local_base_dir}{folder}\"\n",
        "\n",
        "\n",
        "# Specify the filename of interest, leave blank if all files should be in scope\n",
        "filename = \"device.view.lkml\" #@param {type:\"string\"}\n",
        "\n",
        "file_paths = []\n",
        "\n",
        "# If both folder and filename are provided, search only in that folder for the specific filename\n",
        "if folder and filename:\n",
        "      print(f\"Searching for {filename} in folder: {folder_path}\")\n",
        "      file_paths = glob.glob(os.path.join(folder_path, \"**\", filename), recursive=True)\n",
        "\n",
        "# If folder is provided and filename is not, search all files in the folder recursively\n",
        "elif folder:\n",
        "    print(f\"Searching for all files in folder: {folder_path}\")\n",
        "    file_paths = glob.glob(os.path.join(folder_path, \"**\", \"*.view.lkml\"), recursive=True)\n",
        "\n",
        "# If filename is provided and folder is not, search for that file across all folders\n",
        "elif filename:\n",
        "        print(f\"Searching for {filename} across all folders.\")\n",
        "        file_paths = glob.glob(os.path.join(\"**\", filename), recursive=True)\n",
        "\n",
        "# If neither folder nor filename is provided, search all .view.lkml files across all folders\n",
        "else:\n",
        "    print(\"Searching for all .view.lkml files across all folders.\")\n",
        "    file_paths = glob.glob(\"**/*.view.lkml\", recursive=True)\n",
        "\n",
        "\n",
        "file_paths = [os.path.abspath(file) for file in file_paths]\n",
        "print(file_paths)\n"
      ],
      "metadata": {
        "id": "2kLqEc2Nj9H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# File where matched dimesions, dimesion groups and measure should be written to\n",
        "output_file = f\"{local_base_dir}identical_fields.lkml\"\n",
        "print(output_file)"
      ],
      "metadata": {
        "id": "rZkiKi_sDK5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run comparison process\n",
        "\n",
        "compare_lookml_files(file_paths,output_file)"
      ],
      "metadata": {
        "id": "NhYVhGfoFH9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from git import Repo\n",
        "\n",
        "def commit_and_push_changes(local_base_dir, commit_message, branch):\n",
        "    \"\"\"Stages and commits changes, then pushes to the remote repository.\"\"\"\n",
        "\n",
        "    # Open the local Git repository\n",
        "    repo = Repo(local_base_dir)\n",
        "\n",
        "    # Ensure the correct branch is checked out\n",
        "    if branch not in repo.branches:\n",
        "        print(f\"‚ö†Ô∏è Branch '{branch}' does not exist locally. Creating and checking it out.\")\n",
        "        # Create and checkout the branch based on the current branch (usually 'main' or 'master')\n",
        "        repo.git.checkout('HEAD', b=branch)\n",
        "    else:\n",
        "        print(f\"‚úÖ Branch '{branch}' exists. Checking it out.\")\n",
        "        # Checkout the branch if it exists\n",
        "        repo.git.checkout(branch)\n",
        "\n",
        "    # Check if the repository is dirty (i.e., there are changes to commit)\n",
        "    if repo.is_dirty():\n",
        "        print(\"üö® Repository has uncommitted changes.\")\n",
        "\n",
        "        # Stage all the changes\n",
        "        repo.git.add(A=True)  # Add all changes (including new files, modified files)\n",
        "        print(\"Staged changes.\")\n",
        "\n",
        "        # Commit the changes\n",
        "        try:\n",
        "            repo.index.commit(commit_message)\n",
        "            print(f\"‚úÖ Changes committed: {commit_message}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error committing changes: {e}\")\n",
        "            return\n",
        "\n",
        "        # Push the changes to the remote repository\n",
        "        try:\n",
        "            origin = repo.remote(name='origin')\n",
        "            origin.push(branch)\n",
        "            print(f\"‚úÖ Changes pushed to branch: {branch}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error pushing changes: {e}\")\n",
        "    else:\n",
        "        print(\"No changes detected. Repository is clean.\")\n",
        "\n",
        "# Example usage:\n",
        "commit_message = \"Updated LookML files with consolidated objects\"\n",
        "branch = \"dev-brendan-buckley-pnpg\"  #@param {trpe: \"string\"}\n",
        "\n",
        "commit_and_push_changes(local_base_dir, commit_message, branch)\n"
      ],
      "metadata": {
        "id": "ENagGcL9xgs5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}